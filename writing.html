<!DOCTYPE html>
<html lang="en-GB">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Writing - Julie Hendry | Interim CIO</title>
  <meta name="description" content="Writing on technology, organisations, and AI workforce impact. Lab Notes from beò and earlier work from Cow Consulting.">
  <meta property="og:title" content="Writing - Julie Hendry">
  <meta property="og:description" content="Selected writing on technology, organisations, and the space between them.">
  <meta property="og:image" content="https://juliehendry.com/images/og-image.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <link rel="icon" href="favicon.svg" type="image/svg+xml">
  <link rel="canonical" href="https://juliehendry.com/writing.html">
  <link rel="stylesheet" href="css/styles.css">
</head>
<body>

  <a href="#content" class="skip-link">Skip to content</a>

  <nav class="site-nav" role="navigation">
    <div class="nav-inner">
      <a href="index.html" class="site-name">Julie Hendry</a>
      <button class="nav-toggle" aria-label="Toggle navigation" onclick="document.querySelector('.nav-links').classList.toggle('open')">
        <span></span><span></span><span></span>
      </button>
      <ul class="nav-links">
        <li><a href="index.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="work.html">Work</a></li>
        <li><a href="writing.html" class="active">Writing</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
    </div>
  </nav>

  <main id="content">

  <header class="page-header">
    <div class="container">
      <h1>Writing</h1>
      <p class="lead">Selected writing on technology, organisations, and the space between them.</p>
    </div>
  </header>

  <section class="section">
    <div class="container narrow">

      <article class="work-block">
        <div class="era-label">beò Lab Notes · 17 February 2026</div>
        <h3>Your AI Rollout Has a Measurement Problem</h3>
        <p>You've rolled out ChatGPT Enterprise, GitHub Copilot, or Gemini across your teams. Or you're about to. You've probably run an employee survey: "How satisfied are you with the new AI tools?" Maybe you're tracking adoption metrics: logins, prompts per day, features used.</p>
        <p>None of that tells you what you actually need to know.</p>
        <p>Satisfaction surveys measure sentiment. Adoption dashboards measure usage. Neither measures whether AI is changing how your people <em>think</em>.</p>
        <p>Is your engineering team losing the ability to debug without AI assistance? Are your analysts less confident in decisions they made themselves? Is your team's collective knowledge getting shallower because everyone's relying on the same tool for the same answers?</p>
        <p>These are cognitive questions. And right now, most organisations deploying AI have no way to answer them.</p>
        <p>In 2020, we ran a study comparing what people <em>believed</em> about their smartphone use to what they <em>actually did</em>. The widely used "addiction" questionnaires showed almost no correlation with real behaviour (r = .12). The tools the field relied on were measuring the wrong thing entirely.</p>
        <p>The same pattern is playing out in enterprise AI adoption. Employee satisfaction surveys tell you how people <em>feel</em> about generative AI tools. They don't tell you whether those tools are changing how your workforce thinks, decides, and collaborates. That gap between perception and reality is where the risk lives.</p>
        <p>These aren't hypothetical concerns. Early research on AI-assisted decision making suggests that over-reliance on AI recommendations can reduce critical thinking and create automation bias. The question isn't whether this will affect your workforce. It's whether you'll notice before it becomes a problem.</p>
        <p>If you're deploying AI tools in 2026, you have a narrow window. You can measure cognitive baselines <em>before</em> AI adoption changes them, or you can try to reconstruct what changed after the fact. One gives you evidence. The other gives you guesswork.</p>
        <p>We're running this as a research study, not a consultancy engagement. Pre-registered methodology on the Open Science Framework. Published findings. Validated instruments. The same rigour you'd expect from an academic study, applied to your organisation.</p>
        <a href="https://beo.llc/blog/your-ai-rollout-has-a-measurement-problem.html" class="work-link">Read the full post at beò</a>
      </article>

      <article class="work-block">
        <div class="era-label">beò Lab Notes · 5 February 2026</div>
        <h3>Why I Stopped Chasing 'Addiction'</h3>
        <p>In 2020, I ran my MSc research convinced I'd prove everyone was addicted to their phones. I used multiple validated measures, including the BSMAS, MTUAS, and a Stroop test, and collected actual iPhone Screen Time data. I was ready.</p>
        <p>The BSMAS "addiction" scores showed weak correlation with actual social media screen time (r = .12). But the MTUAS frequency questions, simply asking "how often do you check social media?", correlated well (r = .54).</p>
        <p>I was confused. The headline finding was unexpected.</p>
        <p>People weren't in denial. They could report their social media frequency fairly accurately. But the distress measured by "addiction" scales wasn't the same as how much they actually used it.</p>
        <p>The addiction framing, borrowed from gambling research in the early 2010s, measures psychological distress about technology. But distress isn't the same as behaviour. You can feel terrible about your phone while using it moderately. You can feel fine while scrolling for hours.</p>
        <p>In 2023, researchers validated something different: the Digital Flourishing Scale. Instead of measuring pathology, it measures whether technology supports meaningful relationships, authentic self-expression, and sense of purpose. The Self-Control subscale specifically asks whether you feel in control of your digital life.</p>
        <p>The question shifted from "how broken are you?" to "is technology helping you live well?"</p>
        <p>My 2020 self would have built another shame-based app showing scary numbers.</p>
        <p>Instead, beò asks: do you feel like technology is serving your life? Can simple microhabits, breathing, movement, nature, connection, shift that feeling?</p>
        <p>I'm not measuring screen time reduction (research shows "digital detox" apps struggle with this anyway). I'm measuring whether you feel more in control. Whether technology feels like it's working for you.</p>
        <p>I'm using the latest validated measures (2023, peer-reviewed, published in Journal of Happiness Studies). The older framework led me to findings that didn't make sense. When better tools exist, use them.</p>
        <p>We're pre-registering our hypotheses, acknowledging our limitations (self-selected sample, no control group, 4-week duration), and sharing what we find, including what doesn't work.</p>
        <p>That's the kind of research I want to do.</p>
        <a href="https://beo.llc/blog/why-i-stopped-chasing-addiction.html" class="work-link">Read the full post at beò</a>
      </article>

      <article class="work-block">
        <div class="era-label">beò Lab Notes · 28 January 2026</div>
        <h3>From Research to Reality</h3>
        <p>Ask someone how often they check social media and they'll tell you with reasonable accuracy. Ask them whether their phone use is "problematic" and their answer will have almost nothing to do with how much they actually use it.</p>
        <p>That's the perception gap. And it's the reason most digital wellbeing interventions don't work.</p>
        <p>We recruited 82 iPhone users aged 18 to 30. They completed validated questionnaires and provided screenshots of their actual Screen Time data. When we compared what people reported to what they actually did, a pattern emerged.</p>
        <p>Participants' self-reported social media use strongly correlated with their actual iPhone data (screen time, notifications, pickups). People could accurately report how often they used social media. But self-reported smartphone addiction scores showed no significant correlation with actual iPhone usage. The questionnaires designed to measure "problematic use" didn't predict actual behaviour.</p>
        <p>There's a fundamental disconnect between what users <em>believe</em> about their smartphone habits and what they <em>actually</em> do. People can report their social media frequency accurately, but addiction-based assessments don't reflect reality.</p>
        <p>This research became beò's founding hypothesis: we need to close the perception gap first. This isn't just another app telling you to use your phone less. It's a research study testing whether understanding leads to meaningful change.</p>
        <p>beò is what happens when academic research meets enterprise engineering. I spent 20+ years building technology for Fortune 500 companies. I know how to ship reliable systems at scale. The MSc taught me research rigour: methodology, ethics, statistical power, ecological validity.</p>
        <p>Now I'm building the tool I needed to test whether this approach works. Not as a commercial product first, but as a research study. We'll publish findings. We'll share what works and what doesn't. We'll contribute to the evidence base instead of adding to the noise.</p>
        <p>That's the point of research: testing ideas properly, not selling solutions.</p>
        <a href="https://beo.llc/blog/from-research-to-reality.html" class="work-link">Read the full post at beò</a>
      </article>

    </div>
  </section>

  <section class="section section-alt">
    <div class="container narrow">

      <div class="section-header">
        <div class="label">2009 &ndash; 2014</div>
        <h2>Earlier Writing</h2>
      </div>

      <article class="work-block">
        <div class="era-label">Cow Consulting</div>
        <h3>The 10 to 6 Effect</h3>
        <p>Many years ago I had the fortunate experience of working with a hyper-productive and wonderfully lovely team of about 100 people. The first thing that happened was the leaders of the group asked the people to choose their working hours.</p>
        <p>Immediately this group of people had a puzzle to solve. The puzzle had one specific outcome: what times will we be working from tomorrow onwards? There were constraints. Every two weeks everyone had to share their work and plan together between 9am and 5pm. Some wanted flexible hours. Most wanted to work with other people. As the conversations flowed people started discussing their personal needs. Long commutes, picking up kids, rush hour traffic, prayer needs, health problems.</p>
        <p>As humanity and empathy emerged, deep thought and dialogue became infectious. They decided they'd rather work together all the time if they could. The most popular vote was 10am until 6pm. Management accepted. This acceptance initiated the building of trust. It paid off in later iterations when the teams would help each other get stories over the line. It gave everyone permission to ask for what they needed to do the job.</p>
        <p>So I ask you: ditch the theories for a moment, stop looking for methods, and know you cannot force people to change. Try a single, simple act of leadership instead.</p>
      </article>

      <article class="work-block">
        <div class="era-label">Cow Consulting</div>
        <h3>Learning Together Creates a Better Future</h3>
        <p>Some volunteers arrived in a small village in Africa. Their aim? To tackle the childhood malnutrition that besieged the area. Others had been before them. People who lectured, people who taught, people who tried their best to get the villagers to do things their way. But the people resisted and no-one knew why.</p>
        <p>A smart young volunteer observed that a few of the local babies seemed well fed. She proceeded to learn the language and communicate with the families. As trust grew, she discovered they would take a local insect and grind it into the milk. The village knew this form of protein was edible, yet deemed it beneath them.</p>
        <p>With the volunteer's help, the mothers of the well-fed children stood up and told their neighbours what they had done. Some courageous first followers tried in secret. Soon the village had much less problems with malnutrition.</p>
        <p>I love this story because it shows how simply taking time to see, and being open to the unthinkable, can make the difference. Even in our world, it is just better to do things with the people involved. Not to them. Be open. Be courageous.</p>
      </article>

      <div class="archive-notice">
        More posts from the Cow Consulting archive are being recovered. They'll appear here as they're restored, in their original form.
      </div>

    </div>
  </section>

  </main>

  <footer class="site-footer">
    <div class="container">
      <div class="footer-inner">
        <span>&copy; 2026 Julie Hendry</span>
        <span><a href="privacy.html">Privacy</a> · <a href="https://www.linkedin.com/in/juliehendry/" target="_blank" rel="noopener">LinkedIn</a> · <a href="contact.html">Let's talk</a></span>
      </div>
    </div>
  </footer>

<!-- Cloudflare Web Analytics --><script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "81084ceafb55402ead83aefb2e03347b"}'></script><!-- End Cloudflare Web Analytics -->
</body>
</html>
